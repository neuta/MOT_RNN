{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee333496",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256b6a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:51:49.572688Z",
     "start_time": "2022-03-24T21:51:49.074857Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b64a2571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T15:39:49.451606Z",
     "start_time": "2022-03-25T15:39:49.445536Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b0613",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29fa21c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:51:55.970950Z",
     "start_time": "2022-03-24T21:51:55.916494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([133, 5, 9]) <class 'torch.Tensor'>\n",
      "torch.Size([133, 9]) <class 'torch.Tensor'>\n",
      "------------------------------------------------------------\n",
      "torch.Size([133, 5, 7])\n",
      "torch.Size([133, 7])\n"
     ]
    }
   ],
   "source": [
    "X_Data = np.loadtxt(\"X_Training.txt\", dtype=np.float32)\n",
    "Y_Data = np.loadtxt(\"Y_Training.txt\", dtype=np.float32)\n",
    "\n",
    "Features = 9 # Information: Frame, Track ID, 3D Dimensions (H, W, L), 3D Location (X,Y,Z), Rotation Y\n",
    "X_Data = X_Data.reshape(X_Data.shape[0], X_Data.shape[1] // Features, Features)\n",
    "\n",
    "X_Data = torch.tensor(X_Data)\n",
    "Y_Data = torch.tensor(Y_Data)\n",
    "\n",
    "print(X_Data.shape, type(X_Data))\n",
    "print(Y_Data.shape, type(Y_Data))\n",
    "print('-'.center(60,'-'))\n",
    "# Information: 3D Dimensions (H, W, L), 3D Location (X,Y,Z), Rotation Y\n",
    "X_Data = X_Data[:,:,2:9]\n",
    "Y_Data = Y_Data[:,2:9]\n",
    "\n",
    "print(X_Data.shape)\n",
    "print(Y_Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9066ab",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347021b",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0442c85c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T22:01:50.895711Z",
     "start_time": "2022-03-24T22:01:50.886913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 5, 7])\n",
      "torch.Size([125, 7])\n",
      "torch.Size([25, 5, 5, 7])\n",
      "torch.Size([25, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "data_x = X_Data[0:125]\n",
    "data_y = Y_Data[0:125]\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\n",
    "batch_size = 125\n",
    "lote = 5\n",
    "t = data_x.reshape(int(batch_size/lote),5,5,7)\n",
    "o = data_y.reshape(int(batch_size/lote),lote,7)\n",
    "\n",
    "print(t.shape)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30621ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:31:48.405575Z",
     "start_time": "2022-03-25T16:31:48.396799Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        \n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim #Hidden Dimension\n",
    "        self.layer_dim = layer_dim # Number of hidden layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu') #Building the RNN       \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # Readout layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initializing the hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        #One time step (the last one perhaps?)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Indexing hidden state of the last time step\n",
    "        # out.size() --> ??\n",
    "        #out[:,-1,:] --> is it going to be 100,100\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        # out.size() --> 100,1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57b35282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:31:49.187615Z",
     "start_time": "2022-03-25T16:31:49.182835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = 7\n",
    "hidden_dim = 150\n",
    "layer_dim = 1\n",
    "output_dim = 7\n",
    "batch_size = 25\n",
    "seq_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fedfbc28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:31:50.201780Z",
     "start_time": "2022-03-25T16:31:50.192193Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([133, 5, 7])\n",
      "torch.Size([1, 7])\n",
      "tensor([[-0.0013, -0.0141, -0.3464,  0.4851, -0.3214,  0.2022,  0.3500]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Input Test\n",
    "x = X_Data[0]\n",
    "x = x.reshape(1,5,7)\n",
    "x.shape\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "out = model(x)\n",
    "print(X_Data.shape)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c9c7fcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:31:51.321069Z",
     "start_time": "2022-03-25T16:31:51.313992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([133, 1, 5, 7])\n",
      "torch.Size([133, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "\n",
    "batch_size = 133\n",
    "lote = 1\n",
    "\n",
    "XT_Data = X_Data.reshape(int(batch_size/lote),lote,5,7)\n",
    "YT_Data = Y_Data.reshape(int(batch_size/lote),lote,7)\n",
    "print(t.shape)\n",
    "print(o.shape)\n",
    "\n",
    "X_train = XT_Data[:100]\n",
    "X_test  = XT_Data[101:]\n",
    "y_train = YT_Data[:100]\n",
    "y_test  = YT_Data[101:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18575c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:31:52.476569Z",
     "start_time": "2022-03-25T16:31:52.472357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating Loss Class\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Instantiate Optimizer Class\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "160ab243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:31:53.651576Z",
     "start_time": "2022-03-25T16:31:53.610000Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i,(X, Y) in enumerate(zip(XT_Data, YT_Data)):\n",
    "        \n",
    "#         print('-'.center(60,'-'))\n",
    "        if (i+1) % 100 == 0:\n",
    "#             print('Hola',i)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09791c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:34:00.971726Z",
     "start_time": "2022-03-25T16:33:46.612072Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch [1/200], Step [100/100], Loss: 0.0033\n",
      "------------------------------------------------------------\n",
      "Epoch [2/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [3/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [4/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [5/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [6/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [7/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [8/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [9/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [10/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [11/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [12/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [13/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [14/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [15/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [16/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [17/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [18/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [19/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [20/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [21/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [22/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [23/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [24/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [25/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [26/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [27/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [28/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [29/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [30/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [31/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [32/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [33/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [34/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [35/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [36/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [37/200], Step [100/100], Loss: 0.0029\n",
      "------------------------------------------------------------\n",
      "Epoch [38/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [39/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [40/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [41/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [42/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [43/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [44/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [45/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [46/200], Step [100/100], Loss: 0.0030\n",
      "------------------------------------------------------------\n",
      "Epoch [47/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [48/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [49/200], Step [100/100], Loss: 0.0031\n",
      "------------------------------------------------------------\n",
      "Epoch [50/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [51/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [52/200], Step [100/100], Loss: 0.0032\n",
      "------------------------------------------------------------\n",
      "Epoch [53/200], Step [100/100], Loss: 0.0033\n",
      "------------------------------------------------------------\n",
      "Epoch [54/200], Step [100/100], Loss: 0.0033\n",
      "------------------------------------------------------------\n",
      "Epoch [55/200], Step [100/100], Loss: 0.0033\n",
      "------------------------------------------------------------\n",
      "Epoch [56/200], Step [100/100], Loss: 0.0033\n",
      "------------------------------------------------------------\n",
      "Epoch [57/200], Step [100/100], Loss: 0.0033\n",
      "------------------------------------------------------------\n",
      "Epoch [58/200], Step [100/100], Loss: 0.0034\n",
      "------------------------------------------------------------\n",
      "Epoch [59/200], Step [100/100], Loss: 0.0034\n",
      "------------------------------------------------------------\n",
      "Epoch [60/200], Step [100/100], Loss: 0.0034\n",
      "------------------------------------------------------------\n",
      "Epoch [61/200], Step [100/100], Loss: 0.0034\n",
      "------------------------------------------------------------\n",
      "Epoch [62/200], Step [100/100], Loss: 0.0034\n",
      "------------------------------------------------------------\n",
      "Epoch [63/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [64/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [65/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [66/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [67/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [68/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [69/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [70/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [71/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [72/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [73/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [74/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [75/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [76/200], Step [100/100], Loss: 0.0035\n",
      "------------------------------------------------------------\n",
      "Epoch [77/200], Step [100/100], Loss: 0.0036\n",
      "------------------------------------------------------------\n",
      "Epoch [78/200], Step [100/100], Loss: 0.0036\n",
      "------------------------------------------------------------\n",
      "Epoch [79/200], Step [100/100], Loss: 0.0036\n",
      "------------------------------------------------------------\n",
      "Epoch [80/200], Step [100/100], Loss: 0.0036\n",
      "------------------------------------------------------------\n",
      "Epoch [81/200], Step [100/100], Loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch [82/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [83/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [84/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [85/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [86/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [87/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [88/200], Step [100/100], Loss: 0.0037\n",
      "------------------------------------------------------------\n",
      "Epoch [89/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [90/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [91/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [92/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [93/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [94/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [95/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [96/200], Step [100/100], Loss: 0.0038\n",
      "------------------------------------------------------------\n",
      "Epoch [97/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [98/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [99/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [100/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [101/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [102/200], Step [100/100], Loss: 0.0039\n",
      "------------------------------------------------------------\n",
      "Epoch [103/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [104/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [105/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [106/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [107/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [108/200], Step [100/100], Loss: 0.0041\n",
      "------------------------------------------------------------\n",
      "Epoch [109/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [110/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [111/200], Step [100/100], Loss: 0.0041\n",
      "------------------------------------------------------------\n",
      "Epoch [112/200], Step [100/100], Loss: 0.0041\n",
      "------------------------------------------------------------\n",
      "Epoch [113/200], Step [100/100], Loss: 0.0040\n",
      "------------------------------------------------------------\n",
      "Epoch [114/200], Step [100/100], Loss: 0.0041\n",
      "------------------------------------------------------------\n",
      "Epoch [115/200], Step [100/100], Loss: 0.0041\n",
      "------------------------------------------------------------\n",
      "Epoch [116/200], Step [100/100], Loss: 0.0042\n",
      "------------------------------------------------------------\n",
      "Epoch [117/200], Step [100/100], Loss: 0.0042\n",
      "------------------------------------------------------------\n",
      "Epoch [118/200], Step [100/100], Loss: 0.0043\n",
      "------------------------------------------------------------\n",
      "Epoch [119/200], Step [100/100], Loss: 0.0042\n",
      "------------------------------------------------------------\n",
      "Epoch [120/200], Step [100/100], Loss: 0.0043\n",
      "------------------------------------------------------------\n",
      "Epoch [121/200], Step [100/100], Loss: 0.0043\n",
      "------------------------------------------------------------\n",
      "Epoch [122/200], Step [100/100], Loss: 0.0043\n",
      "------------------------------------------------------------\n",
      "Epoch [123/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [124/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [125/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [126/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [127/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [128/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [129/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [130/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [131/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [132/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [133/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [134/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [135/200], Step [100/100], Loss: 0.0044\n",
      "------------------------------------------------------------\n",
      "Epoch [136/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [137/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [138/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [139/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [140/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [141/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [142/200], Step [100/100], Loss: 0.0045\n",
      "------------------------------------------------------------\n",
      "Epoch [143/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [144/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [145/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [146/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [147/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [148/200], Step [100/100], Loss: 0.0047\n",
      "------------------------------------------------------------\n",
      "Epoch [149/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [150/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [151/200], Step [100/100], Loss: 0.0047\n",
      "------------------------------------------------------------\n",
      "Epoch [152/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [153/200], Step [100/100], Loss: 0.0046\n",
      "------------------------------------------------------------\n",
      "Epoch [154/200], Step [100/100], Loss: 0.0047\n",
      "------------------------------------------------------------\n",
      "Epoch [155/200], Step [100/100], Loss: 0.0047\n",
      "------------------------------------------------------------\n",
      "Epoch [156/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [157/200], Step [100/100], Loss: 0.0047\n",
      "------------------------------------------------------------\n",
      "Epoch [158/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [159/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [160/200], Step [100/100], Loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch [161/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [162/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [163/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [164/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [165/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [166/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [167/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [168/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [169/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [170/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [171/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [172/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [173/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [174/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [175/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [176/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [177/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [178/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [179/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [180/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [181/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [182/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [183/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [184/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [185/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [186/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [187/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [188/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [189/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [190/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [191/200], Step [100/100], Loss: 0.0048\n",
      "------------------------------------------------------------\n",
      "Epoch [192/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [193/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [194/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [195/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [196/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [197/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [198/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [199/200], Step [100/100], Loss: 0.0049\n",
      "------------------------------------------------------------\n",
      "Epoch [200/200], Step [100/100], Loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "# initializing lists to store losses over epochs:\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_iter = []\n",
    "test_iter = []\n",
    "\n",
    "n_total_steps = len(X_train)\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i,(X, Y) in enumerate(zip(X_train, y_train)):\n",
    "        \n",
    "#         print('-'.center(60,'-'))       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)  \n",
    "\n",
    "        \n",
    "        loss = criterion(outputs,Y)\n",
    "#         print(loss)\n",
    "        \n",
    "        train_loss.append(loss.data.tolist())\n",
    "\n",
    "        \n",
    "        # Backward and optimize        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('-'.center(60,'-'))       \n",
    "            \n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43e08836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:32:32.381594Z",
     "start_time": "2022-03-25T16:32:32.280544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss,'-')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.title('Training loss vs Iterations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c4fbd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2cb03d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:34:21.951746Z",
     "start_time": "2022-03-23T22:34:21.941119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, num_classes, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # assuming batch_first = True for RNN cells\n",
    "        x = x.permute(1, 0, 2) \n",
    "        batch_size = x.size(1)\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        \n",
    "\n",
    "        rnn_out, _ = self.rnn(x, hidden)\n",
    "        linear_out = self.linear(rnn_out.view(-1, hidden_size))\n",
    "        return linear_out\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.num_layers, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "86c3ad66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:34:33.863289Z",
     "start_time": "2022-03-23T22:34:33.856831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "seq_len = 5    \n",
    "input_size = 7   \n",
    "batch_size = 5  \n",
    "num_layers = 1   \n",
    "num_classes = 7  \n",
    "hidden_size = 133  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "15717716",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T22:34:35.835670Z",
     "start_time": "2022-03-23T22:34:35.797765Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 5, 133), got [133, 1, 133]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-58af3c2cb17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pcdet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-99bb578ae4aa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlinear_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlinear_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pcdet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pcdet/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pcdet/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pcdet/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    221\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 5, 133), got [133, 1, 133]"
     ]
    }
   ],
   "source": [
    "model = RNN(seq_len, num_classes, input_size, hidden_size, num_layers)\n",
    "logits = model(X_Data)\n",
    "print(logits[0:7])\n",
    "print(logits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be3d34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "out = model(X_Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c32cc6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b686f400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T18:59:56.651980Z",
     "start_time": "2022-03-24T18:59:56.639337Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "               \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d72bcfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T18:59:59.145069Z",
     "start_time": "2022-03-24T18:59:59.140105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 7\n",
    "num_epochs = 2\n",
    "batch_size = 133\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 7\n",
    "sequence_length = 5\n",
    "hidden_size = 128\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f403340f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T19:00:00.760109Z",
     "start_time": "2022-03-24T19:00:00.314594Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([133, 5, 7])\n",
      "torch.Size([133, 7])\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "out = model(X_Data)\n",
    "print(X_Data.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07892c97",
   "metadata": {},
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "588ebb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T20:51:35.945444Z",
     "start_time": "2022-03-24T20:51:35.941412Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b81cef",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ad937",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76bd8220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T19:00:13.785957Z",
     "start_time": "2022-03-24T19:00:13.776682Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 5, 7])\n",
      "torch.Size([125, 7])\n"
     ]
    }
   ],
   "source": [
    "data_x = X_Data[0:125]\n",
    "data_y = Y_Data[0:125]\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb984fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T20:51:00.047905Z",
     "start_time": "2022-03-24T20:51:00.040384Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 5, 5, 7])\n",
      "torch.Size([25, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([25, 5, 5, 7])\n",
    "# torch.Size([25, 5, 7])\n",
    "\n",
    "batch_size = 125\n",
    "lote = 5\n",
    "t = data_x.reshape(int(batch_size/lote),5,5,7)\n",
    "o = data_y.reshape(int(batch_size/lote),lote,7)\n",
    "print(t.shape)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "483db87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T19:44:48.138357Z",
     "start_time": "2022-03-24T19:44:48.122375Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[133, 1, 7]' is invalid for input of size 4655",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-fbfb1984d202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_Data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_Data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[133, 1, 7]' is invalid for input of size 4655"
     ]
    }
   ],
   "source": [
    "batch_size = len(X_Data)\n",
    "lote = 1\n",
    "t = X_Data.reshape(int(batch_size/lote),lote,5,7)\n",
    "o = X_Data.reshape(int(batch_size/lote),lote,7)\n",
    "print(t.shape)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046893f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a371709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T20:51:19.367215Z",
     "start_time": "2022-03-24T20:51:19.362325Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initializing lists to store losses over epochs:\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_iter = []\n",
    "test_iter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7e4dd1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:03:38.834178Z",
     "start_time": "2022-03-24T21:03:38.728707Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "tensor(0.2193, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2786, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.6638, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(2.5502, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(2.1736, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(8.2186, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0303, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1203, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1476, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1566, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1661, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(2.9446, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.8476, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.3551, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.3482, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.3185, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.4650, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2348, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2384, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1169, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0883, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.3605, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1977, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2517, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2370, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.5990, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(2.3781, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(1.9016, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(7.6564, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0324, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1288, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1809, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1655, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1559, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(2.7456, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.8620, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.3306, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.3061, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.5885, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.6483, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2247, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2430, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0709, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.0853, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.2498, grad_fn=<MseLossBackward>)\n",
      "------------------------------------------------------------\n",
      "tensor(0.1560, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# initializing lists to store losses over epochs:\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_iter = []\n",
    "test_iter = []\n",
    "\n",
    "n_total_steps = len(t)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i,(X, Y) in enumerate(zip(t, o)):\n",
    "        \n",
    "        print('-'.center(60,'-'))       \n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(X)  \n",
    "#         print(outputs.shape,labels.shape)\n",
    "#         print(outputs,labels.shape)\n",
    "        \n",
    "        loss = criterion(outputs,Y)\n",
    "        print(loss)\n",
    "        \n",
    "        # Backward and optimize        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "       \n",
    "        train_loss.append(loss.data.tolist())\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            \n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, n_total_steps, loss.item()))\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf61d23",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7155bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fe36e349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T21:09:30.978166Z",
     "start_time": "2022-03-24T21:09:30.971854Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9addd7",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5e4c92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T15:45:13.319093Z",
     "start_time": "2022-03-25T15:45:13.274099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i,(X, Y) in enumerate(zip(t, o)):\n",
    "\n",
    "        inputs = X\n",
    "        labels = Y\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs.data\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f22129cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:35:23.753319Z",
     "start_time": "2022-03-25T16:35:23.747309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 7])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c141955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:35:29.228538Z",
     "start_time": "2022-03-25T16:35:29.222582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 7])\n",
      "tensor([[[ 1.5000,  1.6750,  4.0267, -5.0587,  1.7490, 23.0131,  1.4844],\n",
      "         [ 1.5000,  1.6750,  4.0267, -5.4528,  1.7523, 22.3591,  1.4661],\n",
      "         [ 1.5000,  1.6750,  4.0267, -5.8468,  1.7556, 21.7051,  1.4479],\n",
      "         [ 1.5000,  1.6750,  4.0267, -6.2329,  1.7587, 20.9865,  1.4297],\n",
      "         [ 1.5000,  1.6750,  4.0267, -6.6190,  1.7619, 20.2679,  1.4115]]])\n"
     ]
    }
   ],
   "source": [
    "ee = X_test[1].reshape(1,5,7)\n",
    "print(ee.shape)\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d34053f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:35:39.610291Z",
     "start_time": "2022-03-25T16:35:39.603322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6049,  1.6089,  4.1472, -6.7411,  1.9087, 19.5274,  1.4149]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(ee)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783670bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c7edb8",
   "metadata": {},
   "source": [
    "# Save the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7a81c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:35:59.804966Z",
     "start_time": "2022-03-25T16:35:59.697730Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dcdbace1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:49:32.154220Z",
     "start_time": "2022-03-25T16:49:32.148420Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,   \n",
    "            },'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf72824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcdet",
   "language": "python",
   "name": "pcdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
